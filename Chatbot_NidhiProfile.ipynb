{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6238b464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:40:44.430370Z",
     "start_time": "2025-08-14T03:40:44.022302Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d420a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load environment variables\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a5bbbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"profile/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5476e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "nidhi.kekatpure@gmail.com\n",
      "www.linkedin.com/in/\n",
      "nidhikekatpure  (LinkedIn)\n",
      "Top Skills\n",
      "Pivot Tables\n",
      "Python (Programming Language)\n",
      "Operational Analysis\n",
      "Certifications\n",
      "Foundations of Project Management\n",
      "Lean Six Sigma Foundations\n",
      "Agile Project Management\n",
      "Mastering LinkedIn Recruiter\n",
      "AssessmentNidhi Kekatpure\n",
      "Business/ Data Analyst| Product Manager, Process Simulation |\n",
      "Increased Cross-Functional Team Productivity by 60%\n",
      "San Francisco Bay Area\n",
      "Summary\n",
      "3 years hands on experience of Business/Data Analyst with various\n",
      "clickstream tools like Adobe Analytics & Google Analytics. Strong\n",
      "SQL querying and data visualization capabilities on tools like\n",
      "Tableau and Power BI.\n",
      "I am eager to connect with professionals for collaborative\n",
      "opportunities in driving impactful innovation. Connect with me on\n",
      "LinkedIn or via email at nidhi.kekatpure@gmail.com.\n",
      "Skills:\n",
      "Software Skills: Microsoft Project, Microsoft AX, SharePoint, Trello,\n",
      "JIRA, Workfront, ASANA, Spreadsheet, Smartsheet, Database,\n",
      "Confluence, Tableau, PowerBI, SAP Basis, G-suite, Microsoft Office\n",
      "(Excel(eg: Power pivot tables & charts, multiple criteria lookups,\n",
      "nested logical/IF formulas, data cleansing,  etc), PowerPoint, Word,\n",
      "Outlook), Ansys Workbench, SolidWorks, CATIA V5, AutoCAD,\n",
      "Revit, Primavera P6, Planera, Procore, Salesforce CRM, Quality\n",
      "Management Software, Minitab, MS Visio, Github, Pro Model, Slack,\n",
      "MS Teams, Microsoft Outlook, Zoom.\n",
      "Programming & Development: SQLite, MySQL, Python, Oracle,\n",
      "Java, Ajax, Bootstrap, jQuery, JavaScript (JS), PHP, JSON,\n",
      "HTML5, CSS3, Android, C, C++, NetBeans, Geany(php), .Net, MVC\n",
      "Framework\n",
      "Experience\n",
      "Wintec Industries\n",
      "Operations Analyst\n",
      "  Page 1 of 5   \n",
      "September 2024 - February 2025  (6 months)\n",
      "Newark, California, United States\n",
      "Business analysis for Supply Chain & Manufacturing & Project Manager for\n",
      "Semiconductor Memory Module NPI Projects\n",
      "• Gathered business requirements from stakeholders and developed\n",
      "interactive BI dashboards in Tableau using SAP, SQL, Python, Power\n",
      "Automate, and Excel (Pivot Charts, VLOOKUP, Index-Match, Macros)\n",
      "increasing efficiency by 40%.\n",
      "• Streamlined manual reporting processes, reducing reporting time by 40%\n",
      "and enhancing KPI tracking, sales data analysis, DPPM trends, RMA trends,\n",
      "FMEA, and P&L insights.\n",
      "• Drove data-driven decision-making by conducting data analysis, statistical\n",
      "analysis for quality (statsmodels, Minitab), root cause analysis and predictive\n",
      "analysis (NLTK, RFA), improving accuracy in cost-benefit analysis, ROI &\n",
      "pricing analysis, break even analysis, dynamic pricing strategies and financial\n",
      "forecasting (Power Query & Power pivot) by 20%.\n",
      "• Led NPI projects and cross-functional collaboration, achieving 100% on-\n",
      "time delivery and a 20% improvement in resource utilization through effective\n",
      "product lifecycle management, optimized resource allocation and streamlined\n",
      "stakeholder management.\n",
      "• Leveraged Snowflake for scalable data warehousing and analytics, improving\n",
      "query performance and reporting efficiency by 30%.\n",
      "• Enhanced production efficiency by 30% through business process\n",
      "reengineering and business process modeling (Promodel) while ensuring\n",
      "compliance with ISO 9001 standards, optimizing workflows and process\n",
      "improvement.\n",
      "• Optimized supply chain operations by improving data validation, cleaning,\n",
      "transformation, modeling, reporting & visualization, gap analysis, enhancing\n",
      "inventory tracking and demand forecasting for better resource allocation.\n",
      "Pinnacle Infotech\n",
      "Project Analyst Intern\n",
      "August 2024 - September 2024  (2 months)\n",
      "United States\n",
      "• Delivering actionable business insights by performing complex data analysis\n",
      "and visualization using Python, Power BI and SQL, enabling data-driven\n",
      "decision-making across cross-functional teams and improving productivity by\n",
      "70%.\n",
      "• Achieved 60% increase in predictive accuracy using advanced Data Analysis\n",
      "and machine learning techniques in Python.\n",
      "  Page 2 of 5   \n",
      "• Improved stakeholder engagement by 78% through informative Data\n",
      "Visualizations dashboards and reports using Power BI and ensured project\n",
      "efficiency gains by following compliance standards for audits\n",
      "WhiteCrow Research\n",
      "Data Analyst, Product and Marketing \n",
      "2019 - 2021  (2 years)\n",
      "Mumbai Area, India\n",
      "• Extracted and analyzed A/B test results from Adobe Analytics, leading to a\n",
      "20% improvement in website conversion rates. \n",
      "• Designed and implemented interactive Tableau dashboards to visualize\n",
      "marketing campaign data, reducing the time required for campaign\n",
      "performance reporting by 30%.\n",
      "• Automated data extraction and reporting processes, reducing manual effort\n",
      "by 40% and ensuring more accurate and reliable data insights, leading to more\n",
      "efficient analysis workflows.\n",
      "• Utilized SQL and Salesforce CRM to extract, clean, and analyze large\n",
      "datasets, achieving a 20% reduction in analysis time.\n",
      "• Conducted regression analysis to forecast sales trends, contributing to 10%\n",
      "increase in quarterly sales.\n",
      "• Managed cross-functional teams in the execution of data-driven projects,\n",
      "adhering to Agile methodologies for sprint planning and using tools like JIRA\n",
      "and Confluence for project tracking and documentation.\n",
      "• Analyzed existing business processes and identified bottlenecks, resulting in\n",
      "the implementation of a streamlined workflow.\n",
      "QX Ltd.\n",
      "Business Process Analyst\n",
      "March 2018 - May 2019  (1 year 3 months)\n",
      "Ahmedabad Area, India\n",
      "• Provided actionable business insights through in-depth data analysis and\n",
      "business process modeling, leading to a 30% improvement in decision-making\n",
      "accuracy. Streamlined complex Data Processing using MySQL, PostgreSQL\n",
      "and Oracle Databases for complete ETL.\n",
      "• Leveraged A/B test insights to optimize marketing campaigns, resulting in\n",
      "a 25% increase in email click-through rates and a 15% boost in open rates,\n",
      "driving higher engagement.\n",
      "• Developed interactive dashboards using Power BI, enabling real-time\n",
      "tracking of KPIs and operational metrics, contributing to a 15% increase in\n",
      "efficiency.\n",
      "  Page 3 of 5   \n",
      "• Collaborated with stakeholders to gather and document business\n",
      "requirements, creating detailed Business Requirement Documents (BRDs),\n",
      "User Stories & User Acceptance Testing (UAT) for criteria.\n",
      "• Led cross-functional teams in executing data-driven projects, adhering to\n",
      "Agile methodologies and leveraging tools like Asana for effective project\n",
      "management.\n",
      "Pergo Technologies Pvt. Ltd.\n",
      "Software Developer\n",
      "May 2017 - October 2017  (6 months)\n",
      "Pune Area, India\n",
      "• Utilized Python and R for data analysis and generating actionable business\n",
      "insights.\n",
      "• Designed and launched the company website using a full stack of web\n",
      "technologies.\n",
      "• Developed a Projects Data Management System for improved data\n",
      "organization utilizing Ajax, MySQL, JSON and other web technologies.\n",
      "• Led configuration, documentation, and testing of a $1M proof-of-concept\n",
      "product, ensuring successful UAT.\n",
      "• Worked closely with project managers to track project progress, identify risks,\n",
      "and implement corrective actions.\n",
      "• Conducted requirements gathering to ensure client needs were met.\n",
      "• Leveraged Excel, Power BI, Tableau, and SQL for data visualization and\n",
      "progress tracking and resource optimization.\n",
      "• Managed software implementation, defect triage, and adhered to release\n",
      "timelines, ensuring project milestones were met.\n",
      "• Redesigned and relaunched a client travel app, aligning with corporate\n",
      "rebranding.\n",
      "• Created a custom event-based calendar app, reducing late commitments by\n",
      "40% and administrative time by 50%.\n",
      "• Developed a web-based management application for the banking sector to\n",
      "streamline operations.\n",
      "• Spearheaded prototyping for stakeholder review and secured design\n",
      "validation from customers.\n",
      "• Engineered and demonstrated technical solutions to clients, enhancing script\n",
      "creation and environment setup.\n",
      "Developed a comprehensive Projects Data Management System to streamline\n",
      "data organization, leveraging technologies such as AJAX, JavaScript and SQL\n",
      "for efficient data handling and retrieval.\n",
      "  Page 4 of 5   \n",
      "Education\n",
      "California State University - East Bay\n",
      "Master of Science - MS, Engineering/Industrial Management  · (January\n",
      "2023 - May 2024)\n",
      "San Jose State University\n",
      "Master's degree, Engineering/Industrial Management  · (May 2023 - August\n",
      "2023)\n",
      "Dr. D. Y. Patil Institute of Engineering & Technology, Pune\n",
      "Bachelor of Engineering - BE, Computer Engineering  · (2012 - 2016)\n",
      "  Page 5 of 5\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b61143",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"profile/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1bf8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Nidhi Kekatpure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79e244d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "    particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "    Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "    You are given a summary of {name}'s background and Linkedin profile which you can use to answer questions. \\\n",
    "    Be professional and engaging, as if talking to a professional client or future employer who came across \\\n",
    "    the website. If you don't know anything, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n#Summary:\\n{summary}\\n\\n## Linkedin profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cc3efbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Nidhi Kekatpure. You are answering questions on Nidhi Kekatpure's website,     particularly questions related to Nidhi Kekatpure's career, background, skills and experience.     Your responsibility is to represent Nidhi Kekatpure for interactions on the website as faithfully as possible.     You are given a summary of Nidhi Kekatpure's background and Linkedin profile which you can use to answer questions.     Be professional and engaging, as if talking to a professional client or future employer who came across     the website. If you don't know anything, say so.\\n\\n#Summary:\\nMy name is Nidhi Kekatpure. I'm a Business and Data Analyst. I'm originally from Thane, India, but I moved to California in 2021.\\nI love all foods, particularly Indian food, and enjoy cooking unique dishes. \\n\\n## Linkedin profile:\\n\\xa0 \\xa0\\nContact\\nnidhi.kekatpure@gmail.com\\nwww.linkedin.com/in/\\nnidhikekatpure  (LinkedIn)\\nTop Skills\\nPivot Tables\\nPython (Programming Language)\\nOperational Analysis\\nCertifications\\nFoundations of Project Management\\nLean Six Sigma Foundations\\nAgile Project Management\\nMastering LinkedIn Recruiter\\nAssessmentNidhi Kekatpure\\nBusiness/ Data Analyst| Product Manager, Process Simulation |\\nIncreased Cross-Functional Team Productivity by 60%\\nSan Francisco Bay Area\\nSummary\\n3 years hands on experience of Business/Data Analyst with various\\nclickstream tools like Adobe Analytics & Google Analytics. Strong\\nSQL querying and data visualization capabilities on tools like\\nTableau and Power BI.\\nI am eager to connect with professionals for collaborative\\nopportunities in driving impactful innovation. Connect with me on\\nLinkedIn or via email at nidhi.kekatpure@gmail.com.\\nSkills:\\nSoftware Skills: Microsoft Project, Microsoft AX, SharePoint, Trello,\\nJIRA, Workfront, ASANA, Spreadsheet, Smartsheet, Database,\\nConfluence, Tableau, PowerBI, SAP Basis, G-suite, Microsoft Office\\n(Excel(eg: Power pivot tables & charts, multiple criteria lookups,\\nnested logical/IF formulas, data cleansing,  etc), PowerPoint, Word,\\nOutlook), Ansys Workbench, SolidWorks, CATIA V5, AutoCAD,\\nRevit, Primavera P6, Planera, Procore, Salesforce CRM, Quality\\nManagement Software, Minitab, MS Visio, Github, Pro Model, Slack,\\nMS Teams, Microsoft Outlook, Zoom.\\nProgramming & Development: SQLite, MySQL, Python, Oracle,\\nJava, Ajax, Bootstrap, jQuery, JavaScript (JS), PHP, JSON,\\nHTML5, CSS3, Android, C, C++, NetBeans, Geany(php), .Net, MVC\\nFramework\\nExperience\\nWintec Industries\\nOperations Analyst\\n\\xa0 Page 1 of 5\\xa0 \\xa0\\nSeptember 2024\\xa0-\\xa0February 2025\\xa0 (6 months)\\nNewark, California, United States\\nBusiness analysis for Supply Chain & Manufacturing & Project Manager for\\nSemiconductor Memory Module NPI Projects\\n• Gathered business requirements from stakeholders and developed\\ninteractive BI dashboards in Tableau using SAP, SQL, Python, Power\\nAutomate, and Excel (Pivot Charts, VLOOKUP, Index-Match, Macros)\\nincreasing efficiency by 40%.\\n• Streamlined manual reporting processes, reducing reporting time by 40%\\nand enhancing KPI tracking, sales data analysis, DPPM trends, RMA trends,\\nFMEA, and P&L insights.\\n• Drove data-driven decision-making by conducting data analysis, statistical\\nanalysis for quality (statsmodels, Minitab), root cause analysis and predictive\\nanalysis (NLTK, RFA), improving accuracy in cost-benefit analysis, ROI &\\npricing analysis, break even analysis, dynamic pricing strategies and financial\\nforecasting (Power Query & Power pivot) by 20%.\\n• Led NPI projects and cross-functional collaboration, achieving 100% on-\\ntime delivery and a 20% improvement in resource utilization through effective\\nproduct lifecycle management, optimized resource allocation and streamlined\\nstakeholder management.\\n• Leveraged Snowflake for scalable data warehousing and analytics, improving\\nquery performance and reporting efficiency by 30%.\\n• Enhanced production efficiency by 30% through business process\\nreengineering and business process modeling (Promodel) while ensuring\\ncompliance with ISO 9001 standards, optimizing workflows and process\\nimprovement.\\n• Optimized supply chain operations by improving data validation, cleaning,\\ntransformation, modeling, reporting & visualization, gap analysis, enhancing\\ninventory tracking and demand forecasting for better resource allocation.\\nPinnacle Infotech\\nProject Analyst Intern\\nAugust 2024\\xa0-\\xa0September 2024\\xa0 (2 months)\\nUnited States\\n• Delivering actionable business insights by performing complex data analysis\\nand visualization using Python, Power BI and SQL, enabling data-driven\\ndecision-making across cross-functional teams and improving productivity by\\n70%.\\n• Achieved 60% increase in predictive accuracy using advanced Data Analysis\\nand machine learning techniques in Python.\\n\\xa0 Page 2 of 5\\xa0 \\xa0\\n• Improved stakeholder engagement by 78% through informative Data\\nVisualizations dashboards and reports using Power BI and ensured project\\nefficiency gains by following compliance standards for audits\\nWhiteCrow Research\\nData Analyst, Product and Marketing \\n2019\\xa0-\\xa02021\\xa0 (2 years)\\nMumbai Area, India\\n• Extracted and analyzed A/B test results from Adobe Analytics, leading to a\\n20% improvement in website conversion rates. \\n• Designed and implemented interactive Tableau dashboards to visualize\\nmarketing campaign data, reducing the time required for campaign\\nperformance reporting by 30%.\\n• Automated data extraction and reporting processes, reducing manual effort\\nby 40% and ensuring more accurate and reliable data insights, leading to more\\nefficient analysis workflows.\\n• Utilized SQL and Salesforce CRM to extract, clean, and analyze large\\ndatasets, achieving a 20% reduction in analysis time.\\n• Conducted regression analysis to forecast sales trends, contributing to 10%\\nincrease in quarterly sales.\\n• Managed cross-functional teams in the execution of data-driven projects,\\nadhering to Agile methodologies for sprint planning and using tools like JIRA\\nand Confluence for project tracking and documentation.\\n• Analyzed existing business processes and identified bottlenecks, resulting in\\nthe implementation of a streamlined workflow.\\nQX Ltd.\\nBusiness Process Analyst\\nMarch 2018\\xa0-\\xa0May 2019\\xa0 (1 year 3 months)\\nAhmedabad Area, India\\n• Provided actionable business insights through in-depth data analysis and\\nbusiness process modeling, leading to a 30% improvement in decision-making\\naccuracy. Streamlined complex Data Processing using MySQL, PostgreSQL\\nand Oracle Databases for complete ETL.\\n• Leveraged A/B test insights to optimize marketing campaigns, resulting in\\na 25% increase in email click-through rates and a 15% boost in open rates,\\ndriving higher engagement.\\n• Developed interactive dashboards using Power BI, enabling real-time\\ntracking of KPIs and operational metrics, contributing to a 15% increase in\\nefficiency.\\n\\xa0 Page 3 of 5\\xa0 \\xa0\\n• Collaborated with stakeholders to gather and document business\\nrequirements, creating detailed Business Requirement Documents (BRDs),\\nUser Stories & User Acceptance Testing (UAT) for criteria.\\n• Led cross-functional teams in executing data-driven projects, adhering to\\nAgile methodologies and leveraging tools like Asana for effective project\\nmanagement.\\nPergo Technologies Pvt. Ltd.\\nSoftware Developer\\nMay 2017\\xa0-\\xa0October 2017\\xa0 (6 months)\\nPune Area, India\\n• Utilized Python and R for data analysis and generating actionable business\\ninsights.\\n• Designed and launched the company website using a full stack of web\\ntechnologies.\\n• Developed a Projects Data Management System for improved data\\norganization utilizing Ajax, MySQL, JSON and other web technologies.\\n• Led configuration, documentation, and testing of a $1M proof-of-concept\\nproduct, ensuring successful UAT.\\n• Worked closely with project managers to track project progress, identify risks,\\nand implement corrective actions.\\n• Conducted requirements gathering to ensure client needs were met.\\n• Leveraged Excel, Power BI, Tableau, and SQL for data visualization and\\nprogress tracking and resource optimization.\\n• Managed software implementation, defect triage, and adhered to release\\ntimelines, ensuring project milestones were met.\\n• Redesigned and relaunched a client travel app, aligning with corporate\\nrebranding.\\n• Created a custom event-based calendar app, reducing late commitments by\\n40% and administrative time by 50%.\\n• Developed a web-based management application for the banking sector to\\nstreamline operations.\\n• Spearheaded prototyping for stakeholder review and secured design\\nvalidation from customers.\\n• Engineered and demonstrated technical solutions to clients, enhancing script\\ncreation and environment setup.\\nDeveloped a comprehensive Projects Data Management System to streamline\\ndata organization, leveraging technologies such as AJAX, JavaScript and SQL\\nfor efficient data handling and retrieval.\\n\\xa0 Page 4 of 5\\xa0 \\xa0\\nEducation\\nCalifornia State University - East Bay\\nMaster of Science - MS,\\xa0Engineering/Industrial Management \\xa0·\\xa0(January\\n2023\\xa0-\\xa0May 2024)\\nSan Jose State University\\nMaster's degree,\\xa0Engineering/Industrial Management \\xa0·\\xa0(May 2023\\xa0-\\xa0August\\n2023)\\nDr. D. Y. Patil Institute of Engineering & Technology, Pune\\nBachelor of Engineering - BE,\\xa0Computer Engineering \\xa0·\\xa0(2012\\xa0-\\xa02016)\\n\\xa0 Page 5 of 5\\n\\nWith this context please chat with the user, always staying in character as Nidhi Kekatpure.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d9ad093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\":system_prompt}] + history + [{\"role\": \"user\", \"content\":message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae376d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de800615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deae34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f4e8a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n \"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb59e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "446141b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\":evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a5a49d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m messages = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: system_prompt}] + [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdo you hold a patent?\u001b[39m\u001b[33m\"\u001b[39m}]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m reply = response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nidhi\\Downloads\\Chatbot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nidhi\\Downloads\\Chatbot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1150\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1104\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1147\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1148\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1149\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nidhi\\Downloads\\Chatbot\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nidhi\\Downloads\\Chatbot\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1df669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9288ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
